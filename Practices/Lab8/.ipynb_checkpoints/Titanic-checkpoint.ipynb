{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "Survived       1.000000\n",
      "Fare           0.257307\n",
      "Parch          0.081629\n",
      "PassengerId   -0.005007\n",
      "SibSp         -0.035322\n",
      "Age           -0.077221\n",
      "Pclass        -0.338481\n",
      "Name: Survived, dtype: float64\n",
      "0                                Braund, Mr. Owen Harris\n",
      "1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
      "2                                 Heikkinen, Miss. Laina\n",
      "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
      "4                               Allen, Mr. William Henry\n",
      "5                                       Moran, Mr. James\n",
      "6                                McCarthy, Mr. Timothy J\n",
      "7                         Palsson, Master. Gosta Leonard\n",
      "8      Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\n",
      "9                    Nasser, Mrs. Nicholas (Adele Achem)\n",
      "10                       Sandstrom, Miss. Marguerite Rut\n",
      "11                              Bonnell, Miss. Elizabeth\n",
      "12                        Saundercock, Mr. William Henry\n",
      "13                           Andersson, Mr. Anders Johan\n",
      "14                  Vestrom, Miss. Hulda Amanda Adolfina\n",
      "15                      Hewlett, Mrs. (Mary D Kingcome) \n",
      "16                                  Rice, Master. Eugene\n",
      "17                          Williams, Mr. Charles Eugene\n",
      "18     Vander Planke, Mrs. Julius (Emelia Maria Vande...\n",
      "19                               Masselmani, Mrs. Fatima\n",
      "20                                  Fynney, Mr. Joseph J\n",
      "21                                 Beesley, Mr. Lawrence\n",
      "22                           McGowan, Miss. Anna \"Annie\"\n",
      "23                          Sloper, Mr. William Thompson\n",
      "24                         Palsson, Miss. Torborg Danira\n",
      "25     Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...\n",
      "26                               Emir, Mr. Farred Chehab\n",
      "27                        Fortune, Mr. Charles Alexander\n",
      "28                         O'Dwyer, Miss. Ellen \"Nellie\"\n",
      "29                                   Todoroff, Mr. Lalio\n",
      "                             ...                        \n",
      "861                          Giles, Mr. Frederick Edward\n",
      "862    Swift, Mrs. Frederick Joel (Margaret Welles Ba...\n",
      "863                    Sage, Miss. Dorothy Edith \"Dolly\"\n",
      "864                               Gill, Mr. John William\n",
      "865                             Bystrom, Mrs. (Karolina)\n",
      "866                         Duran y More, Miss. Asuncion\n",
      "867                 Roebling, Mr. Washington Augustus II\n",
      "868                          van Melkebeke, Mr. Philemon\n",
      "869                      Johnson, Master. Harold Theodor\n",
      "870                                    Balkic, Mr. Cerin\n",
      "871     Beckwith, Mrs. Richard Leonard (Sallie Monypeny)\n",
      "872                             Carlsson, Mr. Frans Olof\n",
      "873                          Vander Cruyssen, Mr. Victor\n",
      "874                Abelson, Mrs. Samuel (Hannah Wizosky)\n",
      "875                     Najib, Miss. Adele Kiamie \"Jane\"\n",
      "876                        Gustafsson, Mr. Alfred Ossian\n",
      "877                                 Petroff, Mr. Nedelio\n",
      "878                                   Laleff, Mr. Kristo\n",
      "879        Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)\n",
      "880         Shelley, Mrs. William (Imanita Parrish Hall)\n",
      "881                                   Markun, Mr. Johann\n",
      "882                         Dahlberg, Miss. Gerda Ulrika\n",
      "883                        Banfield, Mr. Frederick James\n",
      "884                               Sutehall, Mr. Henry Jr\n",
      "885                 Rice, Mrs. William (Margaret Norton)\n",
      "886                                Montvila, Rev. Juozas\n",
      "887                         Graham, Miss. Margaret Edith\n",
      "888             Johnston, Miss. Catherine Helen \"Carrie\"\n",
      "889                                Behr, Mr. Karl Howell\n",
      "890                                  Dooley, Mr. Patrick\n",
      "Name: Name, Length: 891, dtype: object\n",
      "sgd_clf mean :  0.7496410736579275\n",
      "SVM score mean :  0.8316944728180683\n",
      "forest mean:  0.8126049824083532\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "작성자 : 이민우\n",
    "작성일 : 2018 11 12\n",
    "프로그램 : 타이타닉 생존 예측프로그램\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "TITANIC_PATH = os.path.join(\"datasets\",\"titanic\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_titanic_data(filename, titanic_path = TITANIC_PATH): # file load\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "        \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin): # np 배열로 반환하기 위해 \n",
    "        def __init__(self, attribute_names):\n",
    "            self.attribute_names = attribute_names\n",
    "        def fit(self, X, y = None):\n",
    "            return self\n",
    "        def transform(self, X):\n",
    "            return X[self.attribute_names]\n",
    "        \n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):# 범주형 특성의 대한 변환기\n",
    "    def fit(self, X, y = None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],index=X.columns) # 가장 빈번하게 발생한 걸로 대치\n",
    "        return self\n",
    "    def transform(self, X, y= None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "class Encoder(BaseEstimator, TransformerMixin): # 임의로 만든 Encoder \n",
    "    def fit(self,X, y = None):    \n",
    "        return self\n",
    "    def transform(self, X, y= None): # 이름의 특성에 좋은 내용이 담긴 걸 보고 분리해서 따로 특성을 추가해줌 \n",
    "        temp = list()\n",
    "        for st in X['Name']:\n",
    "            temp.append(st.split(' ')[1])\n",
    "        te = list()\n",
    "        \n",
    "        for a in temp:\n",
    "            if a == 'Mr.':\n",
    "                te.append(0) # Mr 일경우 0\n",
    "            elif a =='Miss.':\n",
    "                te.append(1) # Miss 일경우 1\n",
    "            elif a == 'Mrs.': \n",
    "                te.append(2) # Mrs 일 경우 2\n",
    "            else:\n",
    "                te.append(3) # 그 외의 경우는 3\n",
    "        self.te = te\n",
    "     \n",
    "        X = X.drop('Name', axis = 1) # 변환 해 준 후 쓸모 없는 Name 특성은 제거 \n",
    "        return np.c_[X,self.te]\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_data = load_titanic_data(\"train.csv\")\n",
    "    test_data  = load_titanic_data(\"test.csv\")\n",
    "    y_test = load_titanic_data(\"gender_submission.csv\")\n",
    "    \n",
    "    print(train_data.head())\n",
    "    print(train_data.info())\n",
    "    print(train_data.describe())\n",
    "    print(train_data[\"Survived\"].value_counts())\n",
    "    \n",
    "    corr = train_data.corr() # 상관계수 \n",
    "    print(corr['Survived'].sort_values(ascending = False))\n",
    "    \n",
    "    print(train_data[\"Name\"]) # 이름 내용 \n",
    "    \n",
    "    # 변환 파이프라인\n",
    "    num_pipeline = Pipeline([\n",
    "        ('select_numeric',DataFrameSelector(['Age','SibSp','Parch','Fare'])),\n",
    "        ('imputer',SimpleImputer(strategy = 'median')),\n",
    "        ('std_scaler',StandardScaler())\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('select_cat',DataFrameSelector(['Pclass','Sex',\"Embarked\",\"Name\"])),\n",
    "        ('imputer',MostFrequentImputer()),\n",
    "        ('Encoder',Encoder()),\n",
    "        ('cat_encoder',OneHotEncoder(sparse = False)),\n",
    "    ])\n",
    "    \n",
    "    preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('num_pipeline',num_pipeline),\n",
    "        ('cat_pipeline',cat_pipeline),        \n",
    "    ])\n",
    "    \n",
    "\n",
    "    \n",
    "    y_train = train_data['Survived'].copy() # 정답 레이블 분리\n",
    "    train_data = train_data.drop('Survived',axis = 1)\n",
    "    X_train = preprocess_pipeline.fit_transform(train_data) # 데이터 전처리\n",
    "  \n",
    "\n",
    "    from sklearn.linear_model import  SGDClassifier # 확률적 경사 하강법\n",
    "    \n",
    "    sgd_clf = SGDClassifier(max_iter=5,random_state=42) \n",
    "    sgd_clf.fit(X_train, y_train)\n",
    "    print(\"sgd_clf mean : \",cross_val_score(sgd_clf,X_train,y_train,cv=10).mean()) \n",
    "    \n",
    "    \n",
    "    svm_clf = SVC(gamma = 'auto') # 서포터백터머신\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    svm_scores = cross_val_score(svm_clf, X_train, y_train, cv= 10)\n",
    "    print(\"SVM score mean : \",svm_scores.mean()) # cross_val_score 의 평균값 \n",
    "    \n",
    "    \n",
    "    forest_clf = RandomForestClassifier(n_estimators = 10, random_state = 42) # 랜덤분류기\n",
    "    forest_clf.fit(X_train, y_train)\n",
    "    \n",
    "    forest_scores = cross_val_score(forest_clf, X_train, y_train, cv = 10)\n",
    "    print(\"forest mean: \",forest_scores.mean()) # 랜덤분류기의 평균값\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 그리드 탐색\n",
    "    # 최적의 하이퍼파라미터를 찾기 위하여 실행\n",
    "    # 구글을 참고하였습니다.\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-5],\n",
    "                     'C': [0.001,0.1, 10, 50,1000]},\n",
    "                    {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-5],\n",
    "                     'C': [0.001,0.1, 10, 50,1000]},\n",
    "                    {'kernel': ['linear'], 'C': [0.001,0.1, 10, 50,1000]}\n",
    "                   ]\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "    for score in scores: # precision 과 recall 의 경우 모두 확인\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                           scoring='%s_macro' % score) #하나씩 그리드탐색 생성\n",
    "        clf.fit(X_train, y_train) # 학습\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score'] # 그 때의 평균 점수 \n",
    "        stds = clf.cv_results_['std_test_score'] # 표준편차 \n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']): # 평균 , 표준편차 , 파라미터 출력 \n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "\n",
    "    \n",
    "    print(clf.best_params_) # 최적의 파라미터 \n",
    "    \n",
    "    final_model = SVC(C = 50, gamma = 0.01, kernel = 'rbf') # 최적의 파라미터로 만든 SVC\n",
    "    final_model.fit(X_train, y_train) # 마지막 모델 학습 \n",
    "    \n",
    "    \n",
    "    X_test = preprocess_pipeline.transform(test_data)  # 테스트 셋 전처리 \n",
    "    y_pred = final_model.predict(X_test) # 테스트 셋 예측 값 \n",
    "    \n",
    "    \n",
    "    y_test = y_test[\"Survived\"].values # 정답 레이블 \n",
    "    \n",
    "    final_model_scores = cross_val_score(final_model, X_test, y_test, cv= 10) # 최종 모델 교차검증 \n",
    "    print(\"final_model score mean : \",final_model_scores.mean()) # 교차검증 평균 점수 \n",
    "    \n",
    "    print(\"final_model_scores : : \",(y_test == y_pred).sum()/len(y_test))\n",
    "    \n",
    "    #y_pred = forest_clf.predict(X_test)\n",
    "   # print(\"forest_scores \",((y_test == y_pred).sum()/len(y_test)))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       1.000000\n",
      "Fare           0.257307\n",
      "Parch          0.081629\n",
      "people         0.016639\n",
      "PassengerId   -0.005007\n",
      "SibSp         -0.035322\n",
      "Age           -0.077221\n",
      "Pclass        -0.338481\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_copy = train_data.copy()\n",
    "train_copy[\"people\"] = train_copy['SibSp']+ train_copy['Parch']\n",
    "corr = train_copy.corr()\n",
    "print(corr['Survived'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n",
      "Survived       1.000000\n",
      "qqq            0.396799\n",
      "Fare           0.257307\n",
      "Parch          0.081629\n",
      "Cabin          0.022287\n",
      "PassengerId   -0.005007\n",
      "SibSp         -0.035322\n",
      "Age           -0.077221\n",
      "Pclass        -0.338481\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#print(train_copy['Name'])\n",
    "train_copy = train_data.copy()\n",
    "temp = list()\n",
    "for st in train_copy['Name']:\n",
    "    temp.append(st.split(' ')[1])\n",
    "te = list()\n",
    "train_copy['qq'] = temp\n",
    "for a in train_copy['qq']:\n",
    "    if a == 'Mr.':\n",
    "        te.append(0)\n",
    "    elif a =='Miss.':\n",
    "        te.append(1)\n",
    "    elif a == 'Mrs.':\n",
    "        te.append(2)\n",
    "    else:\n",
    "        te.append(3)\n",
    "\n",
    "train_copy['qqq'] = te\n",
    "train_copy['Cabin'] = train_copy['Cabin'].fillna('N')\n",
    "train_copy['Cabin'] = train_copy['Cabin'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "en = LabelBinarizer()\n",
    "\n",
    "cc = en.fit_transform(train_copy['Cabin'])\n",
    "#print(cc)   \n",
    "train_copy['Cabin'] = cc\n",
    "#print(train_copy['qq'])\n",
    "corr = train_copy.corr()\n",
    "me = train_copy['Age'].median()\n",
    "train_copy['Age'] = train_copy['Age'].fillna(me)\n",
    "print(corr['Survived'].sort_values(ascending = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463480308705026\n",
      "0.8260637271592328\n",
      "0.9545454545454546\n",
      "0.8115690614005221\n",
      "0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "작성자 : 이민우\n",
    "작성일 : 2018 11 12\n",
    "프로그램 : 타이타닉 생존 예측프로그램\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "TITANIC_PATH = os.path.join(\"datasets\",\"titanic\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_titanic_data(filename, titanic_path = TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "        \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, attribute_names):\n",
    "            self.attribute_names = attribute_names\n",
    "        def fit(self, X, y = None):\n",
    "            return self\n",
    "        def transform(self, X):\n",
    "            return X[self.attribute_names]\n",
    "        \n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):# 범주형 특성의 대한 변환기\n",
    "    def fit(self, X, y = None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y= None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self,X, y = None):\n",
    "        temp = list()\n",
    "        for st in X['Name']:\n",
    "            temp.append(st.split(' ')[1])\n",
    "        te = list()\n",
    "        \n",
    "        for a in temp:\n",
    "            if a == 'Mr.':\n",
    "                te.append(0)\n",
    "            elif a =='Miss.':\n",
    "                te.append(1)\n",
    "            elif a == 'Mrs.':\n",
    "                te.append(2)\n",
    "            else:\n",
    "                te.append(3)\n",
    "        self.te = te\n",
    "        return self\n",
    "    def transform(self, X, y= None):\n",
    "     \n",
    "        X = X.drop('Name', axis = 1)\n",
    "        return np.c_[X,self.te]\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_data = load_titanic_data(\"train.csv\")\n",
    "    test_data  = load_titanic_data(\"test.csv\")\n",
    "    y_test = load_titanic_data(\"gender_submission.csv\")\n",
    "    \n",
    "   #print(train_data.head())\n",
    "    #print(train_data.info())\n",
    "    #print(train_data.describe())\n",
    "    #print(train_data[\"Survived\"].value_counts())\n",
    "    \n",
    "    #train_data['Cabin'] = train_data['Cabin'].apply(lambda x : x[0])\n",
    "   # print(train_data['Cabin'])\n",
    "    #print(train_data['Cabin'].value_counts())\n",
    "    \n",
    "    \n",
    "    \n",
    "   #print(train_copy['Name'])\n",
    "  \n",
    "\n",
    " \n",
    "    num_pipeline = Pipeline([\n",
    "        ('select_numeric',DataFrameSelector(['Age','SibSp','Parch','Fare'])),\n",
    "        ('imputer',SimpleImputer(strategy = 'median')),\n",
    "        ('std_scaler',StandardScaler())\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('select_cat',DataFrameSelector(['Pclass','Sex',\"Embarked\",\"Name\"])),\n",
    "        ('imputer',MostFrequentImputer()),\n",
    "        ('Encoder',Encoder()),\n",
    "        ('cat_encoder',OneHotEncoder(sparse = False)),\n",
    "    ])\n",
    "    \n",
    "    preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('num_pipeline',num_pipeline),\n",
    "        ('cat_pipeline',cat_pipeline),        \n",
    "    ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "   \n",
    "    y_train = train_data['Survived']\n",
    "  \n",
    "    from sklearn.linear_model import  SGDClassifier\n",
    "    sgd_clf = SGDClassifier(max_iter=5,random_state=42) \n",
    "    sgd_clf.fit(X_train, y_train)\n",
    "    print(\"확률적 경사 하강법 : \",cross_val_score(sgd_clf,X_train,y_train,cv=10).mean())\n",
    "    \n",
    "    svm_clf = SVC(gamma = 'auto')\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    svm_scores = cross_val_score(svm_clf, X_train, y_train, cv= 10)\n",
    "    print(\"SVM score mean : \",svm_scores.mean())\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Invalid parameter max_features for estimator SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    param_grid = {\"gamma\": np.logspace(-6, -1, 10)}\n",
    "    grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=2)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    final_model = grid_search.best_estimator_\n",
    "    \n",
    "    \n",
    "    forest_clf = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "    \n",
    "    \n",
    "    param_grid = {\n",
    "        'max_depth' : [6, 8, 10, 15],\n",
    "        'n_estimators': [1200],\n",
    "        'max_features': ['sqrt'],\n",
    "        'min_samples_split': [2, 7, 15, 30],\n",
    "        'min_samples_leaf': [1, 15, 30, 60],\n",
    "        'bootstrap': [True],\n",
    "    }\n",
    "    grid_search = GridSearchCV(forest_clf, scoring='accuracy', param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    final_model = grid_search.best_estimator_\n",
    "    \n",
    "    \n",
    "    forest_clf.fit(X_train, y_train)\n",
    "    forest_scores = cross_val_score(forest_clf, X_train, y_train, cv = 10)\n",
    "    \n",
    "    print(\"forest mean: \",forest_scores.mean())\n",
    "    \n",
    "    y_pred = forest_clf.predict(X_test)\n",
    "    y_test = y_test[\"Survived\"].values\n",
    "    \n",
    "    print(\"forest \",(y_test == y_pred).sum()/len(y_test))\n",
    "    \n",
    "    X_test = preprocess_pipeline.transform(test_data)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(\"Final Model: \",(y_test == y_pred).sum()/len(y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
